{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid # importando o classificador\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=100, \n",
    "                          n_features=10, \n",
    "                          n_informative=5,\n",
    "                          n_redundant=5,\n",
    "                          n_classes=3, \n",
    "                          weights=[.2,.3,.8]) # Criando dados para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.104069</td>\n",
       "      <td>-1.194625</td>\n",
       "      <td>3.697061</td>\n",
       "      <td>0.445603</td>\n",
       "      <td>-1.844241</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>0.873470</td>\n",
       "      <td>-2.719499</td>\n",
       "      <td>1.135675</td>\n",
       "      <td>-1.056126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.746822</td>\n",
       "      <td>-1.518468</td>\n",
       "      <td>3.548002</td>\n",
       "      <td>1.475839</td>\n",
       "      <td>-0.835393</td>\n",
       "      <td>0.916444</td>\n",
       "      <td>1.750556</td>\n",
       "      <td>-0.850173</td>\n",
       "      <td>-0.635842</td>\n",
       "      <td>-0.369072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.767542</td>\n",
       "      <td>1.002743</td>\n",
       "      <td>-4.931952</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>-2.311636</td>\n",
       "      <td>-4.320033</td>\n",
       "      <td>-1.258448</td>\n",
       "      <td>-1.279753</td>\n",
       "      <td>3.995177</td>\n",
       "      <td>0.246743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948358</td>\n",
       "      <td>-0.282912</td>\n",
       "      <td>1.728514</td>\n",
       "      <td>-1.786941</td>\n",
       "      <td>1.507440</td>\n",
       "      <td>2.665408</td>\n",
       "      <td>-0.586921</td>\n",
       "      <td>-0.143523</td>\n",
       "      <td>-2.425602</td>\n",
       "      <td>0.381564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843444</td>\n",
       "      <td>-2.912575</td>\n",
       "      <td>5.829662</td>\n",
       "      <td>-0.682780</td>\n",
       "      <td>0.417261</td>\n",
       "      <td>1.845350</td>\n",
       "      <td>0.418140</td>\n",
       "      <td>-2.533324</td>\n",
       "      <td>-1.915091</td>\n",
       "      <td>-2.255492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.839165</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>-2.200484</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>-0.618106</td>\n",
       "      <td>-1.993049</td>\n",
       "      <td>-0.334566</td>\n",
       "      <td>0.276066</td>\n",
       "      <td>1.806365</td>\n",
       "      <td>-0.300268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-3.713210</td>\n",
       "      <td>2.205512</td>\n",
       "      <td>-1.447347</td>\n",
       "      <td>1.925537</td>\n",
       "      <td>-0.255308</td>\n",
       "      <td>-1.556903</td>\n",
       "      <td>1.904535</td>\n",
       "      <td>3.768141</td>\n",
       "      <td>2.607606</td>\n",
       "      <td>-0.815599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.127684</td>\n",
       "      <td>-0.637814</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>2.458975</td>\n",
       "      <td>-1.919512</td>\n",
       "      <td>-1.749876</td>\n",
       "      <td>1.370640</td>\n",
       "      <td>-0.558131</td>\n",
       "      <td>1.509329</td>\n",
       "      <td>0.079543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.136673</td>\n",
       "      <td>1.177405</td>\n",
       "      <td>2.047018</td>\n",
       "      <td>0.432825</td>\n",
       "      <td>-1.772691</td>\n",
       "      <td>-0.490160</td>\n",
       "      <td>1.240854</td>\n",
       "      <td>-0.301771</td>\n",
       "      <td>3.678816</td>\n",
       "      <td>-2.006929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.202870</td>\n",
       "      <td>1.101724</td>\n",
       "      <td>1.533106</td>\n",
       "      <td>0.224004</td>\n",
       "      <td>-1.995948</td>\n",
       "      <td>-0.414291</td>\n",
       "      <td>0.819877</td>\n",
       "      <td>-0.945260</td>\n",
       "      <td>3.473813</td>\n",
       "      <td>-1.332091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   3.104069 -1.194625  3.697061  0.445603 -1.844241  0.506878  0.873470   \n",
       "1   0.746822 -1.518468  3.548002  1.475839 -0.835393  0.916444  1.750556   \n",
       "2   0.767542  1.002743 -4.931952  0.851429 -2.311636 -4.320033 -1.258448   \n",
       "3   0.948358 -0.282912  1.728514 -1.786941  1.507440  2.665408 -0.586921   \n",
       "4   0.843444 -2.912575  5.829662 -0.682780  0.417261  1.845350  0.418140   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.839165  0.680886 -2.200484  0.452000 -0.618106 -1.993049 -0.334566   \n",
       "96 -3.713210  2.205512 -1.447347  1.925537 -0.255308 -1.556903  1.904535   \n",
       "97  0.127684 -0.637814  0.051541  2.458975 -1.919512 -1.749876  1.370640   \n",
       "98  1.136673  1.177405  2.047018  0.432825 -1.772691 -0.490160  1.240854   \n",
       "99  2.202870  1.101724  1.533106  0.224004 -1.995948 -0.414291  0.819877   \n",
       "\n",
       "           7         8         9  \n",
       "0  -2.719499  1.135675 -1.056126  \n",
       "1  -0.850173 -0.635842 -0.369072  \n",
       "2  -1.279753  3.995177  0.246743  \n",
       "3  -0.143523 -2.425602  0.381564  \n",
       "4  -2.533324 -1.915091 -2.255492  \n",
       "..       ...       ...       ...  \n",
       "95  0.276066  1.806365 -0.300268  \n",
       "96  3.768141  2.607606 -0.815599  \n",
       "97 -0.558131  1.509329  0.079543  \n",
       "98 -0.301771  3.678816 -2.006929  \n",
       "99 -0.945260  3.473813 -1.332091  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=NearestCentroid() #Criando o Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,y)# Treinando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0,0,0,0,0,1,1,1,1,1]]) #Realizando a predição "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn import svm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t, coef = make_regression(n_samples=100, \n",
    "                                         n_features=3, \n",
    "                                         n_informative=2, # Quantas features, influenciarão no Y, ou seja, estão correlacionados \n",
    "                                         n_targets=1, # Quantos Y ?\n",
    "                                         noise=0.0,\n",
    "                                         coef=True\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store 1</th>\n",
       "      <th>Store 2</th>\n",
       "      <th>Store 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.139303</td>\n",
       "      <td>-0.582862</td>\n",
       "      <td>0.505481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021942</td>\n",
       "      <td>1.234319</td>\n",
       "      <td>0.331884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.130403</td>\n",
       "      <td>-1.240146</td>\n",
       "      <td>-0.540861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.944683</td>\n",
       "      <td>0.084041</td>\n",
       "      <td>1.123645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.017520</td>\n",
       "      <td>1.840628</td>\n",
       "      <td>0.729810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.120050</td>\n",
       "      <td>-0.309553</td>\n",
       "      <td>-0.726085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.023311</td>\n",
       "      <td>-1.886449</td>\n",
       "      <td>1.752523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.488112</td>\n",
       "      <td>2.213759</td>\n",
       "      <td>1.084567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.127490</td>\n",
       "      <td>-1.922203</td>\n",
       "      <td>0.028092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.656168</td>\n",
       "      <td>1.073210</td>\n",
       "      <td>1.408673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store 1   Store 2   Store 3\n",
       "0   2.139303 -0.582862  0.505481\n",
       "1   0.021942  1.234319  0.331884\n",
       "2   1.130403 -1.240146 -0.540861\n",
       "3  -0.944683  0.084041  1.123645\n",
       "4  -2.017520  1.840628  0.729810\n",
       "..       ...       ...       ...\n",
       "95  1.120050 -0.309553 -0.726085\n",
       "96 -0.023311 -1.886449  1.752523\n",
       "97 -0.488112  2.213759  1.084567\n",
       "98  0.127490 -1.922203  0.028092\n",
       "99 -1.656168  1.073210  1.408673\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=['Store 1', 'Store 2', 'Store 3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=svm.SVR() # Criando modelo de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,y) # Treinando o modelo de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35672858])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict([[0,0,1]]) # Realizando a predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() #Carrega o dataset de Íris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o X e y\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train) #ajustes de escala usando os dados de treino\n",
    "X_test_std = sc.fit_transform(X_test) #ajustes de escala usando os dados de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(tol=1e-3, random_state=0) #Cria o perceptron\n",
    "ppn.fit(X_train_std, y_train) # Ajusta o Perceptron com os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = ppn.predict(X_test_std) # realiza a predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando a Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recarga dos datasets\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\paulo\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03csklearn.linear_model._logistic\\nLogisticRegression\\nq\\x00)\\x81q\\x01}q\\x02(X\\x07\\x00\\x00\\x00penaltyq\\x03X\\x02\\x00\\x00\\x00l2q\\x04X\\x04\\x00\\x00\\x00dualq\\x05\\x89X\\x03\\x00\\x00\\x00tolq\\x06G?\\x1a6\\xe2\\xeb\\x1cC-X\\x01\\x00\\x00\\x00Cq\\x07G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00X\\r\\x00\\x00\\x00fit_interceptq\\x08\\x88X\\x11\\x00\\x00\\x00intercept_scalingq\\tK\\x01X\\x0c\\x00\\x00\\x00class_weightq\\nNX\\x0c\\x00\\x00\\x00random_stateq\\x0bNX\\x06\\x00\\x00\\x00solverq\\x0cX\\x05\\x00\\x00\\x00lbfgsq\\rX\\x08\\x00\\x00\\x00max_iterq\\x0eKdX\\x0b\\x00\\x00\\x00multi_classq\\x0fX\\x04\\x00\\x00\\x00autoq\\x10X\\x07\\x00\\x00\\x00verboseq\\x11K\\x00X\\n\\x00\\x00\\x00warm_startq\\x12\\x89X\\x06\\x00\\x00\\x00n_jobsq\\x13NX\\x08\\x00\\x00\\x00l1_ratioq\\x14NX\\x08\\x00\\x00\\x00classes_q\\x15cnumpy.core.multiarray\\n_reconstruct\\nq\\x16cnumpy\\nndarray\\nq\\x17K\\x00\\x85q\\x18C\\x01bq\\x19\\x87q\\x1aRq\\x1b(K\\x01K\\x03\\x85q\\x1ccnumpy\\ndtype\\nq\\x1dX\\x02\\x00\\x00\\x00i4q\\x1eK\\x00K\\x01\\x87q\\x1fRq (K\\x03X\\x01\\x00\\x00\\x00<q!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\"b\\x89C\\x0c\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00q#tq$bX\\x05\\x00\\x00\\x00coef_q%h\\x16h\\x17K\\x00\\x85q&h\\x19\\x87q\\'Rq((K\\x01K\\x03K\\x04\\x86q)h\\x1dX\\x02\\x00\\x00\\x00f8q*K\\x00K\\x01\\x87q+Rq,(K\\x03h!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq-b\\x89C`&\\xb7\\x0c?\\xb0\\xc2\\xda\\xbf\\x8d\\x93\\x94D5\\xec\\xee?}\\x84\\xe7\\x9a\\x10+\\x04\\xc0p\\x94MitX\\xf1\\xbf-\\xbf\\xa5\\xc9+\\xf8\\xe0?\\x91\\xed\\xbeM\\x86\\x1f\\xd4\\xbfgF\\xb2Wn\\x88\\xc9\\xbf,\\xa5\\x96\\xa9YW\\xee\\xbf\\x13\\x1d\\xfbP\\x9d\\xb6\\xbc\\xbf\\xac\\x1c\\xb5\\x1dr\\xdc\\xe4\\xbf\\xaa\\xa8b\\x80\\x97\\xc3\\x05@\\x81s\\x0c\\x9f\\x10B\\x00@q.tq/bX\\n\\x00\\x00\\x00intercept_q0h\\x16h\\x17K\\x00\\x85q1h\\x19\\x87q2Rq3(K\\x01K\\x03\\x85q4h,\\x89C\\x18G\\xc8\\xd1\\xf7\\xef\\xac#@\\xd1\\x13\\x84;\\x08\\xbf\\x01@<\\xce\\xb2\\x06\\xb2\\x1c(\\xc0q5tq6bX\\x07\\x00\\x00\\x00n_iter_q7h\\x16h\\x17K\\x00\\x85q8h\\x19\\x87q9Rq:(K\\x01K\\x01\\x85q;h \\x89C\\x04d\\x00\\x00\\x00q<tq=bX\\x10\\x00\\x00\\x00_sklearn_versionq>X\\x06\\x00\\x00\\x000.22.1q?ub.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = pickle.dumps(clf)\n",
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_from_pickle = pickle.loads(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_from_pickle.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício dos preços das casas em Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visuals as vs # Supplementary code\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 489 data points with 4 variables each.\n"
     ]
    }
   ],
   "source": [
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "print('Boston housing dataset has {} data points with {} variables each.'.format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  LSTAT  PTRATIO\n",
       "0  6.575   4.98     15.3\n",
       "1  6.421   9.14     17.8\n",
       "2  7.185   4.03     17.8\n",
       "3  6.998   2.94     18.7\n",
       "4  7.147   5.33     18.7"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Boston housing dataset:\n",
      "\n",
      "Minimum price: $105,000.00\n",
      "Maximum price: $1,024,800.00\n",
      "Mean price: $454,342.94\n",
      "Median price $438,900.00\n",
      "Standard deviation of prices: $165,171.13\n"
     ]
    }
   ],
   "source": [
    "minimum_price = np.amin(prices)\n",
    "maximum_price = np.amax(prices)\n",
    "mean_price = np.mean(prices)\n",
    "median_price = np.median(prices)\n",
    "std_price = np.std(prices)\n",
    "\n",
    "print (\"Statistics for Boston housing dataset:\\n\")\n",
    "print (\"Minimum price: ${:,.2f}\".format(minimum_price))\n",
    "print (\"Maximum price: ${:,.2f}\".format(maximum_price))\n",
    "print (\"Mean price: ${:,.2f}\".format(mean_price))\n",
    "print (\"Median price ${:,.2f}\".format(median_price))\n",
    "print (\"Standard deviation of prices: ${:,.2f}\".format(std_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a coefficient of determination, R^2, of 0.923.\n"
     ]
    }
   ],
   "source": [
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print (\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing split was successful.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, train_size=0.8, random_state=0)\n",
    "\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-244cbbba60d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\visuals.py\u001b[0m in \u001b[0;36mModelLearning\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Create 10 cross-validation sets for training and testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Generate the training set sizes increasing by 50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "vs.ModelLearning(features, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def dropColumns(xData,dataset):\n",
    "\t# plot the data\n",
    "\tsns.pairplot(dataset,x_vars=xData.columns.values,y_vars=['medv'])\n",
    "\tplt.show()\n",
    "\t# drop the columns that has no relation with the dependent variable\n",
    "\txData=xData.drop(columns=['chas','rad','zn','age','tax','b','indus','nox','crim','dis','ptratio'])\n",
    "\tsns.pairplot(dataset,x_vars=xData.columns.values,y_vars=['medv'])\n",
    "\tplt.show()\n",
    "\treturn xData\n",
    "def dataAnalysis(xData,dataset):\n",
    "\tsns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\tsns.distplot(dataset['medv'], bins=30)\n",
    "\tplt.show()\n",
    "\t#find the correalted variables\n",
    "\tcorelationMatrix=dataset.corr().round(2)\n",
    "\tsns.heatmap(data=corelationMatrix,annot=True)\n",
    "\tplt.show()\n",
    "\txData=dropColumns(xData,dataset)\n",
    "\treturn xData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean squared error is 24.4611\n"
     ]
    }
   ],
   "source": [
    "#read the dataset\n",
    "dataset=pd.read_csv(\"housing.csv\") # carregando os dados com os preços de boston\n",
    "# find dependent and independent variables\n",
    "x=dataset.iloc[:,:-1] # Pegando todas as colunas menos a última (Os valores de x)\n",
    "y=dataset.iloc[:,-1] # Pegando os valores de Y, somente a última coluna\n",
    "# x=dataAnalysis(x,dataset)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=45,train_size=0.7)\n",
    "lr=LinearRegression()# Criando um modelo de regressão\n",
    "#fit the train data\n",
    "lr.fit(x_train,y_train) #treinando o modelo de regressão\n",
    "#predict for the test data\n",
    "y_pred=lr.predict(x_test) #Predizendo os valores dos dados de teste\n",
    "error=mean_squared_error(y_test,y_pred) #calculando o erro da regressão\n",
    "print(\"The Mean squared error is {:.4f}\".format(error)) #imprimindo o erro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
